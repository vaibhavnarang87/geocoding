import numpy as np
import time
import random
import sqlalchemy as db
import pandas as pd
from sqlalchemy import create_engine
import requests
from bs4 import BeautifulSoup
import json

def geocoder(x):
    x = list(x)
    score=0
    ind=0
    geocode=[]
    scr=[]
    loc = []
    town = []
    for r in range(len(x)):
        print(r)
        #time.sleep(random.uniform(0.001,0.025))## random jitter
        #print(r)
        my_dict = {'SingleLine' :x[r],'matchOutOfRange':'true','f':'pjson',}
        url_base = 'https://gis.suffolkcountyny.gov/server/rest/services/Locators/AddressMultiRole/GeocodeServer/findAddressCandidates'
        page = requests.get(url_base,params=my_dict)
        soup = BeautifulSoup(page.content, 'html.parser')
        soup = json.loads(str(soup))
        for k,v in soup.items():
            if k == 'candidates':
                if not v:
                    geocode.append(x[r])
                    scr.append(0)
                    loc.append(0)
                    town.append(0)
                else:
                    for i in range(len(v)):
                        for m,n in v[i].items():
                            if m == 'score':
                                if score < n:
                                    score=n
                                    ind=i
                                else:
                                    i+1
                    for key,value in v[ind].items():
                        if key == 'address':
                            geocode.append(value)
                        elif key == 'score':
                            scr.append(value)
                        elif key == 'location':
                            loc.append(str(value))
                            abc = str(value)
                            my_dict = {'geometry':abc,'geometryType':'esriGeometryPoint','returnGeometry':'false'
                                       ,'spatialRel':'esriSpatialRelIntersects','f':'pjson'}
                            url_base = 'https://gis.suffolkcountyny.gov/server/rest/services/LocalGovernmentSQLData/TownPolygon/FeatureServer/0/query'
                            page = requests.get(url_base,params=my_dict)
                            soup = BeautifulSoup(page.content, 'html.parser')
                            soup = json.loads(str(soup))
                            for k,v in soup.items():
                                if k == 'features':
                                    if v != []:
                                        for key,values in soup.items():
                                            if key == 'features':
                                                for i,j in values[0].items():
                                                    if i == 'attributes':
                                                        for name,typ in j.items():
                                                            town.append(typ)
                                    else:
                                        town.append(0)   

    return(geocode,scr,loc,town)

def geo_parser(a):
    x=(a['single_address'])
    try:
        geocode,scr,loc,town = geocoder(x)
        d = {'Geo_coded_address':geocode,'Score':scr,'Location':loc,'Town':town}
        df_f = pd.DataFrame(data=d)
    except ValueError:
        time.sleep(10)
        geocode,scr,loc,town = geocoder(x)
        d = {'Geo_coded_address':geocode,'Score':scr,'Location':loc,'Town':town}
        df_f = pd.DataFrame(data=d)
    final_df = pd.concat([a.reset_index(drop=True),df_f.reset_index(drop=True)],axis=1)
    final_df .to_sql('nysiis_geocoded_addresses',conn,if_exists='append',index= False)

conn = create_engine('mssql+pymssql://vnarang:%F;=!4hMpGMkpwYm/u7H@HEALTHSQL2:1433/NYSIIS').connect()
#Get data
SQL= r"SELECT a.ID,a.FirstName,a.LastName,a.Dob,a.MailingStreet,a.MailingCity,a.MailingPostalCode,CONCAT(a.MailingStreet,' ',a.MailingCity,' ',a.MailingPostalCode) as single_address FROM [NYSIIS].[dbo].[Vaccine_Addresses]a left join [NYSIIS].[dbo].[nysiis_geocoded_addresses]b on a.ID = b.ID where b.ID is Null"
df = pd.read_sql_query(SQL, conn)
n =df.shape[0]
c=0
n =df.shape[0]
if n == 0:
    exit
elif n > 10000:
    qt = n//10000
    rm = n%10000
    for i in range(qt):
        c = i*10000
        print(i,c)
        a= df[c:c+10000]
        geo_parser(a)
    a_s = df[c+10000:c+10000+rm]
    geo_parser(a_s)
        
elif n>0 & n<10000:
    geo_parser(df)
